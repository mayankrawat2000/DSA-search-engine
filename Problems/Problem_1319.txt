You want to train a neural network model for your graduation work. There are nn images in the dataset, the ii-th image's size is aiai bytes.
You don't have any powerful remote servers to train this model so you have to do it on your local machine. But there is a problem: the total size of the dataset is too big for your machine, so you decided to remove some images — though you don't want to make the dataset too weak so you can remove no more than kk images from it. Note that you can only remove images, you can't change their order.
You want to remove these images optimally so you came up with a metric (you're a data scientist after all) that allows to measure the result of removals. Consider the array b1,b2,…,bmb1,b2,…,bm after removing at most kk images (n−k≤m≤nn−k≤m≤n). The data from this array will be uploaded to the machine in blocks of xx consecutive elements each. More precisely:
  elements with indices from 11 to xx (b1,b2,…,bxb1,b2,…,bx) belong to the first block;  elements with indices from x+1x+1 to 2x2x (bx+1,bx+2,…,b2xbx+1,bx+2,…,b2x) belong to the second block;  elements with indices from 2x+12x+1 to 3x3x (b2x+1,b2x+2,…,b3xb2x+1,b2x+2,…,b3x) belong to the third block;  and so on. 
There will be cnt=⌈mx⌉cnt=⌈mx⌉ blocks in total. Note that if mm is not divisible by xx then the last block contains less than xx elements, and it's okay.
Let w(i)w(i) be the total size of the ii-th block — that is, the sum of sizes of images inside this block. For example, the size of the first block w(1)w(1) is b1+b2+…+bxb1+b2+…+bx, the size of the second block w(2)w(2) is bx+1+bx+2+…+b2xbx+1+bx+2+…+b2x.
The value of the metric you came up with is the maximum block size over the blocks of the resulting dataset. In other words, the value of the metric is maxi=1cntw(i)maxi=1cntw(i).
You don't want to overload your machine too much, so you have to remove at most kk images in a way that minimizes the value of the metric described above.
